{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UE Computer Vision | Project : Visual tracking of video objects\n",
    "\n",
    "Students: Morgane AUBERT, Rogerio KACIAVA BOMBARDELLI, Alex SZAPIRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from path import Path\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import flow_transforms\n",
    "from imageio import imread, imwrite\n",
    "import numpy as np\n",
    "from util import flow2rgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.measure import regionprops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to run the model and evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"./pretrained_model/flownets_EPE1.951.pth.tar\"\n",
    "path_to_sequesnces = \"./sequences-train/\"\n",
    "\n",
    "def dice_assessment(groundtruth, estimated, label=255):\n",
    "    A = groundtruth == label\n",
    "    B = estimated == label\n",
    "    TP = len(np.nonzero(A*B)[0])\n",
    "    FN = len(np.nonzero(A*(~B))[0])\n",
    "    FP = len(np.nonzero((~A)*B)[0])\n",
    "    DICE = 0\n",
    "    if (FP+2*TP+FN) != 0:\n",
    "        DICE = float(2)*TP/(FP+2*TP+FN)\n",
    "    return DICE*100\n",
    "\n",
    "def seg2bmap(seg,width=None,height=None):\n",
    "    \"\"\"\n",
    "    From a segmentation, compute a binary boundary map with 1 pixel wide\n",
    "    boundaries.  The boundary pixels are offset by 1/2 pixel towards the\n",
    "    origin from the actual segment boundary.\n",
    "\n",
    "    Arguments:\n",
    "        seg     : Segments labeled from 1..k.\n",
    "        width   : Width of desired bmap  <= seg.shape[1]\n",
    "        height  : Height of desired bmap <= seg.shape[0]\n",
    "\n",
    "    Returns:\n",
    "        bmap (ndarray):\tBinary boundary map.\n",
    "    \"\"\"\n",
    "\n",
    "    seg = seg.astype(bool)\n",
    "    seg[seg>0] = 1\n",
    "\n",
    "    assert np.atleast_3d(seg).shape[2] == 1\n",
    "\n",
    "    width  = seg.shape[1] if width  is None else width\n",
    "    height = seg.shape[0] if height is None else height\n",
    "\n",
    "    h,w = seg.shape[:2]\n",
    "\n",
    "    ar1 = float(width) / float(height)\n",
    "    ar2 = float(w) / float(h)\n",
    "\n",
    "    assert not (width>w | height>h | abs(ar1-ar2)>0.01),\\\n",
    "        'Can''t convert %dx%d seg to %dx%d bmap.'%(w,h,width,height)\n",
    "\n",
    "    e  = np.zeros_like(seg)\n",
    "    s  = np.zeros_like(seg)\n",
    "    se = np.zeros_like(seg)\n",
    "\n",
    "    e[:,:-1]    = seg[:,1:]\n",
    "    s[:-1,:]    = seg[1:,:]\n",
    "    se[:-1,:-1] = seg[1:,1:]\n",
    "\n",
    "    b        = seg^e | seg^s | seg^se\n",
    "    b[-1,:]  = seg[-1,:]^e[-1,:]\n",
    "    b[:,-1]  = seg[:,-1]^s[:,-1]\n",
    "    b[-1,-1] = 0\n",
    "\n",
    "    if w == width and h == height:\n",
    "        bmap = b\n",
    "    else:\n",
    "        bmap = np.zeros((height,width))\n",
    "        for x in range(w):\n",
    "            for y in range(h):\n",
    "                if b[y,x]:\n",
    "                    j = 1+np.floor((y-1)+height / h)\n",
    "                    i = 1+np.floor((x-1)+width  / h)\n",
    "                    bmap[j,i] = 1\n",
    "\n",
    "    return bmap\n",
    "\n",
    "def centroid_assessment(groundtruth,estimated):\n",
    "    a = regionprops(groundtruth)\n",
    "    b = regionprops(estimated)\n",
    "    return np.linalg.norm(np.array(a[0].centroid)-np.array(b[0].centroid))\n",
    "\n",
    "def db_eval_boundary(foreground_mask,gt_mask,bound_th=0.008):\n",
    "    \"\"\"\n",
    "    Compute mean,recall and decay from per-frame evaluation.\n",
    "    Calculates precision/recall for boundaries between foreground_mask and\n",
    "    gt_mask using morphological operators to speed it up.\n",
    "\n",
    "    Arguments:\n",
    "        foreground_mask (ndarray): binary segmentation image.\n",
    "        gt_mask         (ndarray): binary annotated image.\n",
    "\n",
    "    Returns:\n",
    "        F (float): boundaries F-measure\n",
    "    \"\"\"\n",
    "    assert np.atleast_3d(foreground_mask).shape[2] == 1\n",
    "\n",
    "    bound_pix = bound_th if bound_th >= 1 else \\\n",
    "            np.ceil(bound_th*np.linalg.norm(foreground_mask.shape))\n",
    "\n",
    "    # Get the pixel boundaries of both masks\n",
    "    fg_boundary = seg2bmap(foreground_mask);\n",
    "    gt_boundary = seg2bmap(gt_mask);\n",
    "\n",
    "    from skimage.morphology import binary_dilation,disk\n",
    "\n",
    "    fg_dil = binary_dilation(fg_boundary,disk(bound_pix))\n",
    "    gt_dil = binary_dilation(gt_boundary,disk(bound_pix))\n",
    "\n",
    "    # Get the intersection\n",
    "    gt_match = gt_boundary * fg_dil\n",
    "    fg_match = fg_boundary * gt_dil\n",
    "\n",
    "    # Area of the intersection\n",
    "    n_fg     = np.sum(fg_boundary)\n",
    "    n_gt     = np.sum(gt_boundary)\n",
    "\n",
    "    #% Compute precision and recall\n",
    "    if n_fg == 0 and  n_gt > 0:\n",
    "        precision = 1\n",
    "        recall = 0\n",
    "    elif n_fg > 0 and n_gt == 0:\n",
    "        precision = 0\n",
    "        recall = 1\n",
    "    elif n_fg == 0  and n_gt == 0:\n",
    "        precision = 1\n",
    "        recall = 1\n",
    "    else:\n",
    "        precision = np.sum(fg_match)/float(n_fg)\n",
    "        recall    = np.sum(gt_match)/float(n_gt)\n",
    "\n",
    "    # Compute F measure\n",
    "    if precision + recall == 0:\n",
    "        F = 0\n",
    "    else:\n",
    "        F = 2*precision*recall/(precision+recall);\n",
    "\n",
    "    return F*100.\n",
    "\n",
    "def concatenation(unary_flow, to_ref_flow):\n",
    "    flow = np.zeros((unary_flow.shape[0],unary_flow.shape[1],2), dtype=np.float32)\n",
    "    x0 = np.arange(0, unary_flow.shape[0])\n",
    "    y0 = np.arange(0, unary_flow.shape[1])\n",
    "    xx, yy = np.meshgrid(x0, y0)\n",
    "    z = to_ref_flow[xx,yy,1]\n",
    "    fx = interp2d(x0,y0,z,kind='cubic')\n",
    "    z = to_ref_flow[xx,yy,0]\n",
    "    fy = interp2d(x0,y0,z,kind='cubic')\n",
    "    for x in range(unary_flow.shape[0]):\n",
    "        for y in range(unary_flow.shape[1]):\n",
    "            flow_x = fx(x+unary_flow[x,y,1], y+unary_flow[x,y,0])\n",
    "            flow_y = fy(x+unary_flow[x,y,1], y+unary_flow[x,y,0])\n",
    "            flow[x,y,1] = unary_flow[x,y,1] + flow_x\n",
    "            flow[x,y,0] = unary_flow[x,y,0] + flow_y\n",
    "    return flow\n",
    "\n",
    "def set_cuda():\n",
    "    # setting the cuda device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    return device\n",
    "\n",
    "def load_model(model_path, cuda_device):\n",
    "    # Importing the model\n",
    "    network_data = torch.load(model_path, map_location=cuda_device)\n",
    "    print(\"=> using pre-trained model '{}'\".format(network_data['arch']))\n",
    "    model = models.__dict__[network_data['arch']](network_data).to(cuda_device)\n",
    "    model.eval()\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    if 'div_flow' in network_data.keys():\n",
    "        div_flow = network_data['div_flow']\n",
    "    else:\n",
    "        div_flow = 20.0\n",
    "\n",
    "    return model, div_flow\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(nb_start, nb_end, name_of_the_figure, cuda_device, model, div_flow):\n",
    "    # create the folder for saving the results\n",
    "    path_to_save = Path('my_results')\n",
    "    if not path_to_save.exists():\n",
    "        path_to_save.mkdir()\n",
    "\n",
    "\n",
    "    # Data loading code\n",
    "    input_transform = transforms.Compose([\n",
    "        flow_transforms.ArrayToTensor(),\n",
    "        transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "        transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n",
    "    ])\n",
    "\n",
    "    ###############importing images and nework form the paths################\n",
    "    path_to_sequesnces = \"./sequences-train/\"\n",
    "    name = name_of_the_figure + '-'\n",
    "\n",
    "    \n",
    "    ###############importing images and nework form the paths################\n",
    "    for i in range(nb_start, nb_end):\n",
    "\n",
    "        n_img_1 = i\n",
    "        n_img_2 = i+1\n",
    "\n",
    "        path_img1 = path_to_sequesnces + name + str(n_img_1).zfill(3) + \".bmp\"\n",
    "        path_img2 = path_to_sequesnces + name + str(n_img_2).zfill(3) + \".bmp\"\n",
    "\n",
    "        img1 = imread(path_img1)\n",
    "        img2 = imread(path_img2)\n",
    "        img1 = input_transform(img1)\n",
    "        img2 = input_transform(img2)\n",
    "\n",
    "        input_var = torch.cat([img1, img2]).unsqueeze(0)\n",
    "        input_var = input_var.to(cuda_device)\n",
    "        output = model(input_var)\n",
    "        output = F.interpolate(output, size=img1.size()[-2:], mode = \"bilinear\", align_corners=False)\n",
    "  \n",
    "        flow_output = output.squeeze(0)\n",
    "        \n",
    "        file_name = \"./my_results/\" + name + str(n_img_1).zfill(3) + \"-\" + str(n_img_2).zfill(3)\n",
    "        rgb_flow = flow2rgb(div_flow*flow_output, max_value=None)\n",
    "        to_save_rgb = (rgb_flow * 255).astype(np.uint8).transpose(1,2,0)\n",
    "        imwrite(file_name + '.png', to_save_rgb)\n",
    "\n",
    "        to_save_np = (div_flow*flow_output).cpu().numpy().transpose(1,2,0)\n",
    "        np.save(file_name + '.npy', to_save_np)\n",
    "\n",
    "@torch.no_grad()\n",
    "def simple_inference(img1, img2, name, model, cuda_device, save = False):\n",
    "    div_flow = 20.0\n",
    "    path_to_save = Path('my_results')\n",
    "    if not path_to_save.exists():\n",
    "        path_to_save.mkdir()\n",
    "\n",
    "    # Data loading code\n",
    "    input_transform = transforms.Compose([\n",
    "        flow_transforms.ArrayToTensor(),\n",
    "        transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "        transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n",
    "    ])\n",
    "\n",
    "    img1 = input_transform(img1)\n",
    "    img2 = input_transform(img2)\n",
    "\n",
    "    input_var = torch.cat([img1, img2]).unsqueeze(0)\n",
    "    input_var = input_var.to(cuda_device)\n",
    "    output = model(input_var)\n",
    "    output = F.interpolate(output, size=img1.size()[-2:], mode=\"bilinear\", align_corners=False)\n",
    "    flow_output = output.squeeze(0)\n",
    "\n",
    "    name = \"simple_inference_\" + name\n",
    "    file_name = \"./my_results/\" + name\n",
    "    rgb_flow = flow2rgb(div_flow * flow_output, max_value=None)\n",
    "    to_save_rgb = (rgb_flow * 255).astype(np.uint8).transpose(1, 2, 0)\n",
    "\n",
    "    # Detach the tensor before converting to numpy\n",
    "    to_save_np = (div_flow * flow_output).detach().cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    return  to_save_np\n",
    "    \n",
    "@torch.no_grad()    \n",
    "def complete_inferece_saving_seq(nb_start, nb_end, name):\n",
    "\n",
    "    device = set_cuda()\n",
    "    model, div_flow = load_model(path_to_model, device)\n",
    "    mask = imread(\"./sequences-train/\"+ name +\"-001.png\")\n",
    "\n",
    "    dice_seq, fmeasures_seq, centroid_assessment_seq = [], [], [] #tbt\n",
    "    for i in tqdm(range(nb_start, nb_end)):\n",
    "\n",
    "        n_img_1 = i\n",
    "        n_img_2 = i+1\n",
    "\n",
    "        path_img1 = path_to_sequesnces + name + \"-\" + str(n_img_1).zfill(3) + \".bmp\"\n",
    "        path_img2 = path_to_sequesnces + name + \"-\" + str(n_img_2).zfill(3) + \".bmp\"\n",
    "\n",
    "        mask_cur = imread(\"./sequences-train/\"+ name +\"-\"+ str(n_img_2).zfill(3) +\".png\")\n",
    "\n",
    "        img1 = imread(path_img1)\n",
    "        img2 = imread(path_img2)\n",
    "        black_image = np.zeros((img1.shape[0], img1.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "        flow = simple_inference(img1, img2, name + str(n_img_1).zfill(3), model, device)\n",
    "\n",
    "\n",
    "        if i == 1:\n",
    "            flow_conc = flow\n",
    "        else:\n",
    "            flow_conc = concatenation(flow, flow_conc)\n",
    "\n",
    "        mask_predict = propagate_mask(flow_conc, img_current= img2, mask_begin = mask_cur)\n",
    "        boundaries_predict =  mark_boundaries(black_image, mask_predict, color=(1, 0, 0))\n",
    "        boundaries_gd      =  mark_boundaries(black_image, mask_cur, color=(0, 1, 0)) \n",
    "\n",
    "        imwrite( \"./my_results/\" + name +\"-mask_pro_sequential\"+ str(n_img_2).zfill(3) +'.png', mask_predict)\n",
    "\n",
    "        dice_seq.append(dice_assessment(mask, mask_predict))\n",
    "        fmeasures_seq.append(db_eval_boundary(mask,mask_predict))\n",
    "        centroid_assessment_seq.append(centroid_assessment(mask,mask_predict)) #tbt\n",
    "\n",
    "        np.save(\"./my_results/\" + name + \"-dice_seq.npy\", dice_seq)\n",
    "        np.save(\"./my_results/\" + name + \"-fmeasures_seq.npy\", fmeasures_seq)\n",
    "        np.save(\"./my_results/\" + name + \"-centroid_assessment.npy\", centroid_assessment_seq) #tbt\n",
    "\n",
    "    print(\"ok \" + name)        \n",
    "\n",
    "@torch.no_grad()\n",
    "def inference_direct(nb_start, nb_end, name_of_the_figure, cuda_device, model, div_flow):\n",
    "\n",
    "    # create the folder for saving the results\n",
    "    path_to_save = Path('my_results')\n",
    "    if not path_to_save.exists():\n",
    "        path_to_save.mkdir()\n",
    "\n",
    "\n",
    "    # Data loading code\n",
    "    input_transform = transforms.Compose([\n",
    "        flow_transforms.ArrayToTensor(),\n",
    "        transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "        transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n",
    "    ])\n",
    "\n",
    "    ###############importing images and nework form the paths################\n",
    "    path_to_sequesnces = \"./sequences-train/\"\n",
    "    name = name_of_the_figure + '-'\n",
    "\n",
    "    \n",
    "    ###############importing images and nework form the paths################\n",
    "\n",
    "    n_img_1 = 1\n",
    "    path_img1 = path_to_sequesnces + name + str(n_img_1).zfill(3) + \".bmp\"\n",
    "    img1 = imread(path_img1)\n",
    "    img1 = input_transform(img1)\n",
    "\n",
    "    for i in range(nb_start, nb_end):\n",
    "\n",
    "        n_img_2 = i+1\n",
    "        path_img2 = path_to_sequesnces + name + str(n_img_2).zfill(3) + \".bmp\"\n",
    "        img2 = imread(path_img2)\n",
    "        img2 = input_transform(img2)\n",
    "\n",
    "        input_var = torch.cat([img1, img2]).unsqueeze(0)\n",
    "        input_var = input_var.to(cuda_device)\n",
    "        output = model(input_var)\n",
    "        output = F.interpolate(output, size=img1.size()[-2:], mode = \"bilinear\", align_corners=False)\n",
    "        \n",
    "        flow_output = output.squeeze(0)\n",
    "\n",
    "        file_name = \"./my_results/\" + \"direct\" + name + str(n_img_1).zfill(3) + \"-\" + str(n_img_2).zfill(3)\n",
    "        rgb_flow = flow2rgb(div_flow*flow_output, max_value=None)\n",
    "        to_save_rgb = (rgb_flow * 255).astype(np.uint8).transpose(1,2,0)\n",
    "        imwrite(file_name + '.png', to_save_rgb)\n",
    "\n",
    "        to_save_np = (div_flow*flow_output).cpu().numpy().transpose(1,2,0)\n",
    "        print(file_name + '.npy')\n",
    "        np.save(file_name + '.npy', to_save_np)\n",
    "\n",
    "    print(\"End of flow calculation for direct integration\")\n",
    "\n",
    "\n",
    "def propagate_mask(flow, img_current, mask_begin):\n",
    "    new_mask = np.zeros(shape=img_current.shape[:2], dtype=np.uint8)\n",
    "    for x in range(img_current.shape[0]):\n",
    "        for y in range(img_current.shape[1]):\n",
    "            x_, y_ = np.rint(x+flow[x,y,1]).astype(int), np.rint(y+flow[x,y,0]).astype(int)\n",
    "            if (x_>=0) and (x_<img_current.shape[0]) and (y_>=0) and (y_<img_current.shape[1]):\n",
    "                if mask_begin[x_,y_] > 0:\n",
    "                    new_mask[x,y] = 255\n",
    "    return new_mask\n",
    "\n",
    "\n",
    "def propagate_mask_direct(nb_start, nb_end, name_in_the_figure):\n",
    "    # generate all the propagated masks for the direct method\n",
    "\n",
    "    original_mask = imread(f\"./sequences-train/{name_in_the_figure}-001.png\")\n",
    "    first_img = imread(f'./sequences-train/{name_in_the_figure}-001.bmp')\n",
    "    # imwrite( f\"./my_results/{name_in_the_figure}-mask_pro-001-001.png\", original_mask) # For coherence when reading them later\n",
    "\n",
    "\n",
    "    for i in range(nb_start+1, nb_end+1):\n",
    "        flow = np.load( \"./my_results/\" + \"direct\" + name_in_the_figure + \"-001-\" + str(i).zfill(3) + '.npy')    \n",
    "        current_mask = propagate_mask(flow, img_current= first_img, mask_begin = original_mask)\n",
    "\n",
    "        imwrite( f\"./my_results/{name_in_the_figure}-mask_pro_dir-001-\"+ str(i).zfill(3) +'.png', current_mask)\n",
    "        print(f\"ok {name_in_the_figure}-mask_pro_dir-001-\"+ str(i).zfill(3) +'.png')\n",
    "    print(\"End of mask propagation for direct integration\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference and Evaluatinon of the results using the sequential approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name  = [ \"bear\", \"book\", \"camel\", \"rhino\", \"swan\"]\n",
    "# start = [ 1     ,  1    , 1      , 1      ,  1]  \n",
    "# end   = [ 26    ,  51   , 90     , 90     ,  50]\n",
    "\n",
    "\n",
    "# for i in range(len(name)):\n",
    "#     complete_inferece_saving_seq(start[i], end[i], name[i])\n",
    "\n",
    "# complete_inferece_saving_seq(1,104,\"cow\")\n",
    "\n",
    "# complete_inferece_saving_seq(1,26,\"fish\")\n",
    "\n",
    "complete_inferece_saving_seq(1,26,\"octopus\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_start = 1\n",
    "nb_end   = 50\n",
    "\n",
    "device = set_cuda()\n",
    "model, div_flow = load_model(path_to_model, device)\n",
    "\n",
    "\n",
    "# name  = [ \"bear\", \"book\", \"camel\", \"rhino\", \"swan\"]\n",
    "# start = [ 1     ,  1    , 1      , 1      ,  1]  \n",
    "# end   = [ 26    ,  51   , 90     , 90     ,  50]\n",
    "\n",
    "# for i in range(len(name)):\n",
    "#     inference_direct(start[i], end[i], name[i], device, model, div_flow)\n",
    "#     propagate_mask_direct(start[i], end[i], name[i])\n",
    "\n",
    "\n",
    "inference_direct(1, 104, \"cow\", device, model, div_flow)\n",
    "propagate_mask_direct(1, 104, \"cow\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the dice and f-measure for the direct integration\n",
    "\n",
    "for i in range(len(name)):\n",
    "    mask = imread(\"./sequences-train/\"+ name[i] +\"-001.png\")\n",
    "    dice_dir, fmeasures_dir = [], []\n",
    "    for j in range(start[i]+1, end[i]):\n",
    "        \n",
    "        mask_cur = imread(\"./sequences-train/\"+ name[i] +\"-\"+ str(j).zfill(3) +\".png\")\n",
    "        mask_predict = imread(\"./my_results/\"+ name[i]+ \"-mask_pro_dir-001-\"+ str(j).zfill(3) +'.png')\n",
    "        dice_dir.append(dice_assessment(mask, mask_predict))\n",
    "        fmeasures_dir.append(db_eval_boundary(mask,mask_predict))\n",
    "        np.save(\"./my_results/\" + name[i] + \"-dice_dir.npy\", dice_dir)\n",
    "        np.save(\"./my_results/\" + name[i] + \"-fmeasures_dir.npy\", fmeasures_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results sequential\n",
    "\n",
    "name = [\"bear\", \"book\", \"camel\", \"rhino\", \"swan\"]\n",
    "start = [ 1     ,  1    , 1      , 1      ,  1]  \n",
    "end =   [ 26    ,  51   , 90     , 90     ,  50]\n",
    "\n",
    "\n",
    "for i in range(len(name)):\n",
    "    file_path_dice =\"./my_results/\"+name[i] +\"-dice_seq.npy\"\n",
    "    file_path_fmeasures =\"./my_results/\"+name[i] +\"-fmeasures_seq.npy\"\n",
    "\n",
    "    loaded_array_dice = np.load(file_path_dice)\n",
    "    loaded_array_fmeasure = np.load(file_path_fmeasures)\n",
    "\n",
    "    x = range(start[i]+1,end[i]+1)\n",
    "    print(name[i])\n",
    "    fig, ax = plt.subplots(figsize=(17, 6))\n",
    "    ax.set_title(\"Sequential \" + name[i])\n",
    "    ax.plot(x,loaded_array_dice,marker='o',color='r')\n",
    "    ax.plot(x,loaded_array_fmeasure,marker='v',color='g')\n",
    "    ax.set_xlim((start[i]+1+1,end[i]+1))\n",
    "    ax.set_ylim((0,100))\n",
    "    ax.set_ylabel('score')\n",
    "    ax.set_xlabel(\"im\")\n",
    "    ax.grid()\n",
    "    ax.legend(['dice', 'Fmeasure'])\n",
    "    plt.savefig('results_' + name[i] +'.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Results Direct integration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"bear\", \"book\", \"camel\", \"rhino\", \"swan\"]\n",
    "start = [ 1     ,  1    , 1      , 1      ,  1]  \n",
    "end =   [ 26    ,  51   , 90     , 90     ,  50]\n",
    "\n",
    "\n",
    "for i in range(len(name)):\n",
    "    file_path_dice =\"./my_results/\"+name[i] +\"-dice_dir.npy\"\n",
    "    file_path_fmeasures =\"./my_results/\"+name[i] +\"-fmeasures_dir.npy\"\n",
    "\n",
    "    loaded_array_dice = np.load(file_path_dice)\n",
    "    loaded_array_fmeasure = np.load(file_path_fmeasures)\n",
    "\n",
    "    x = range(start[i]+1,end[i])\n",
    "    print(name[i])\n",
    "    fig, ax = plt.subplots(figsize=(17, 6))\n",
    "    ax.set_title(\"Direct \" + name[i])\n",
    "    ax.plot(x,loaded_array_dice,marker='o',color='r')\n",
    "    ax.plot(x,loaded_array_fmeasure,marker='v',color='g')\n",
    "    ax.set_xlim((start[i]+1+1,end[i]+1))\n",
    "    ax.set_ylim((0,100))\n",
    "    ax.set_ylabel('score')\n",
    "    ax.set_xlabel(\"im\")\n",
    "    ax.grid()\n",
    "    ax.legend(['dice', 'Fmeasure'])\n",
    "    plt.savefig('results_' + name[i] +'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [ \"book\", \"camel\", \"rhino\", \"swan\"]\n",
    "start = [   1    , 1      , 1      ,  1]  \n",
    "end =   [  51   , 90     , 90     ,  50]\n",
    "\n",
    "\n",
    "for i in range(len(name)):\n",
    "\n",
    "    # direct \n",
    "    file_path_dice_d =\"./my_results/\"+name[i] +\"-dice_dir.npy\"\n",
    "    file_path_fmeasures_d =\"./my_results/\"+name[i] +\"-fmeasures_dir.npy\"\n",
    "\n",
    "    loaded_array_dice_d = np.load(file_path_dice_d)\n",
    "    loaded_array_fmeasure_d = np.load(file_path_fmeasures_d)\n",
    "\n",
    "    print(name[i])\n",
    "  \n",
    "\n",
    "    # sequential\n",
    "    file_path_dice_s     =\"./my_results/\"+name[i] +\"-dice_seq.npy\"\n",
    "    file_path_fmeasures_s =\"./my_results/\"+name[i] +\"-fmeasures_seq.npy\"\n",
    "\n",
    "    loaded_array_dice_s = np.load(file_path_dice_s)[:-1]\n",
    "    loaded_array_fmeasure_s = np.load(file_path_fmeasures_s)[:-1]\n",
    "\n",
    "\n",
    "    print(np.shape(loaded_array_dice_d))\n",
    "    print(np.shape(loaded_array_fmeasure_d))\n",
    "    print(np.shape(loaded_array_dice_s))\n",
    "    print(np.shape(loaded_array_fmeasure_s))\n",
    "\n",
    "    x = range(start[i],end[i]-1)\n",
    "    # print(name[i])\n",
    "    print(x)\n",
    "    fig, ax = plt.subplots(figsize=(17, 6))\n",
    "    ax.set_title(\"Sequential X Direct \" + name[i])\n",
    "    ax.plot(x,loaded_array_dice_d,marker='o',color='r')\n",
    "    ax.plot(x,loaded_array_fmeasure_d,marker='v',color='g')\n",
    "\n",
    "    ax.plot(x,loaded_array_dice_s,marker='o',color='b')\n",
    "    ax.plot(x,loaded_array_fmeasure_s,marker='x',color='pink')\n",
    "    \n",
    "\n",
    "    ax.set_xlim((start[i],end[i]-1))\n",
    "    ax.set_ylim((0,100))\n",
    "    ax.set_ylabel('score')\n",
    "    ax.set_xlabel(\"im\")\n",
    "    ax.grid()\n",
    "    ax.legend(['dice direct', 'Fmeasure direct ', 'dice sequential ', 'Fmeasure sequential'])\n",
    "    plt.savefig('results_total_' + name[i] +'.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generatig gifs \n",
    "import imageio\n",
    "\n",
    "\n",
    "# sequential \n",
    "name = [\"bear\", \"book\", \"camel\", \"rhino\", \"swan\"]\n",
    "start = [ 1     ,  1    , 1      , 1      ,  1]  \n",
    "end =   [ 26    ,  51   , 90     , 90     ,  50]\n",
    "\n",
    "\n",
    "j = 3 # rhino\n",
    "rhino_seq_gif = []\n",
    "rhino_dir_gif = []\n",
    "rhino_gd_gif = []\n",
    "for j in range(start[j]+1, end[j]):\n",
    "    rhino_seq_gif.append(imread(\"./my_results/rhino-mask_pro_sequential\"+ str(j).zfill(3) +'.png'))\n",
    "    rhino_dir_gif.append(imread(\"./my_results/rhino-mask_pro_dir-001-\"+ str(j).zfill(3) +'.png'))\n",
    "    rhino_gd_gif.append(imread(\"./sequences-train/\" + name[3]+ \"-\"+ str(j).zfill(3) + \".png\"))\n",
    "\n",
    "\n",
    "# imageio.mimsave('rhino_seq.gif', rhino_seq_gif)\n",
    "# imageio.mimsave('rhino_dir.gif', rhino_dir_gif)\n",
    "# imageio.mimsave('rhino_gd.gif', rhino_gd_gif)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

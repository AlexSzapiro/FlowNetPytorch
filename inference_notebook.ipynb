{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7337/2298950706.py:49: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img1 = imread(path_img1)\n",
      "/tmp/ipykernel_7337/2298950706.py:50: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img2 = imread(path_img2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 samples found\n",
      "cuda\n",
      "=> using pre-trained model 'flownets'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FlowNetS(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv3_1): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv4_1): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv5_1): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv6_1): Sequential(\n",
       "    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (deconv5): Sequential(\n",
       "    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (deconv4): Sequential(\n",
       "    (0): ConvTranspose2d(1026, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (deconv3): Sequential(\n",
       "    (0): ConvTranspose2d(770, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (deconv2): Sequential(\n",
       "    (0): ConvTranspose2d(386, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (predict_flow6): Conv2d(1024, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (predict_flow5): Conv2d(1026, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (predict_flow4): Conv2d(770, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (predict_flow3): Conv2d(386, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (predict_flow2): Conv2d(194, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (upsampled_flow6_to_5): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (upsampled_flow5_to_4): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (upsampled_flow4_to_3): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (upsampled_flow3_to_2): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "from path import Path\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import flow_transforms\n",
    "from imageio import imread, imwrite\n",
    "import numpy as np\n",
    "from util import flow2rgb\n",
    "\n",
    "\n",
    "# myimport \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if name.islower() and not name.startswith(\"__\"))\n",
    "\n",
    "\n",
    "# create the folder for saving the results\n",
    "path_to_save = Path('my_results')\n",
    "if not path_to_save.exists():\n",
    "    path_to_save.mkdir()\n",
    "\n",
    "\n",
    "# Data loading code\n",
    "input_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "    transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n",
    "])\n",
    "\n",
    "###############importing images and nework form the paths################\n",
    "path_to_model = \"./pretrained_model/flownets_EPE1.951.pth.tar\"\n",
    "path_to_sequesnces = \"./sequences-train/\"\n",
    "name = \"swan-\"\n",
    "\n",
    "n_img_1 = 1\n",
    "n_img_2 = 2\n",
    "\n",
    "path_img1 = path_to_sequesnces + name + str(n_img_1).zfill(3) + \".bmp\"\n",
    "path_img2 = path_to_sequesnces + name + str(n_img_2).zfill(3) + \".bmp\"\n",
    "\n",
    "img1 = imread(path_img1)\n",
    "img2 = imread(path_img2)\n",
    "\n",
    "img_pairs = []\n",
    "img_pairs.append([img1, img2])\n",
    "print('{} samples found'.format(len(img_pairs)))\n",
    "###############importing images and nework form the paths################\n",
    "\n",
    "\n",
    "# setting the cuda device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "# Importing the model\n",
    "network_data = torch.load(path_to_model)\n",
    "print(\"=> using pre-trained model '{}'\".format(network_data['arch']))\n",
    "model = models.__dict__[network_data['arch']](network_data).to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import Path\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import flow_transforms\n",
    "from imageio.v2 import imread, imwrite\n",
    "import numpy as np\n",
    "from util import flow2rgb\n",
    "\n",
    "\n",
    "# myimport \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"./pretrained_model/flownets_EPE1.951.pth.tar\"\n",
    "\n",
    "#Load model\n",
    "\n",
    "def set_cuda():\n",
    "    # setting the cuda device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    return device\n",
    "\n",
    "\n",
    "def load_model(model_path, cuda_device):\n",
    "    # Importing the model\n",
    "    network_data = torch.load(model_path, map_location=cuda_device)\n",
    "    print(\"=> using pre-trained model '{}'\".format(network_data['arch']))\n",
    "    model = models.__dict__[network_data['arch']](network_data).to(cuda_device)\n",
    "    model.eval()\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    if 'div_flow' in network_data.keys():\n",
    "        div_flow = network_data['div_flow']\n",
    "    else:\n",
    "        div_flow = 20.0\n",
    "\n",
    "    return model, div_flow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference_direct(nb_start, nb_end, name_of_the_figure, cuda_device, model, div_flow):\n",
    "    # create the folder for saving the results\n",
    "    path_to_save = Path('my_results')\n",
    "    if not path_to_save.exists():\n",
    "        path_to_save.mkdir()\n",
    "\n",
    "\n",
    "    # Data loading code\n",
    "    input_transform = transforms.Compose([\n",
    "        flow_transforms.ArrayToTensor(),\n",
    "        transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "        transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n",
    "    ])\n",
    "\n",
    "    ###############importing images and nework form the paths################\n",
    "    path_to_sequesnces = \"./sequences-train/\"\n",
    "    name = name_of_the_figure + '-'\n",
    "\n",
    "    \n",
    "    ###############importing images and nework form the paths################\n",
    "\n",
    "    n_img_1 = 1\n",
    "    path_img1 = path_to_sequesnces + name + str(n_img_1).zfill(3) + \".bmp\"\n",
    "    img1 = imread(path_img1)\n",
    "    img1 = input_transform(img1)\n",
    "\n",
    "    for i in range(nb_start, nb_end):\n",
    "\n",
    "        n_img_2 = i+1\n",
    "        path_img2 = path_to_sequesnces + name + str(n_img_2).zfill(3) + \".bmp\"\n",
    "        img2 = imread(path_img2)\n",
    "        img2 = input_transform(img2)\n",
    "\n",
    "        input_var = torch.cat([img1, img2]).unsqueeze(0)\n",
    "        input_var = input_var.to(cuda_device)\n",
    "        output = model(input_var)\n",
    "        output = F.interpolate(output, size=img1.size()[-2:], mode = \"bilinear\", align_corners=False)\n",
    "        \n",
    "        flow_output = output.squeeze(0)\n",
    "\n",
    "        file_name = \"./my_results/\" + name + str(n_img_1).zfill(3) + \"-\" + str(n_img_2).zfill(3)\n",
    "        rgb_flow = flow2rgb(div_flow*flow_output, max_value=None)\n",
    "        to_save_rgb = (rgb_flow * 255).astype(np.uint8).transpose(1,2,0)\n",
    "        imwrite(file_name + '.png', to_save_rgb)\n",
    "\n",
    "        to_save_np = (div_flow*flow_output).cpu().numpy().transpose(1,2,0)\n",
    "        np.save(file_name + '.npy', to_save_np)\n",
    "\n",
    "    print(\"End of flow calculation for direct integration\")\n",
    "\n",
    "def propagate_mask(flow, img_current, mask_begin):\n",
    "    new_mask = np.zeros(shape=img_current.shape[:2], dtype=np.uint8)\n",
    "    for x in range(img_current.shape[0]):\n",
    "        for y in range(img_current.shape[1]):\n",
    "            x_, y_ = np.rint(x+flow[x,y,1]).astype(int), np.rint(y+flow[x,y,0]).astype(int)\n",
    "            if (x_>=0) and (x_<img_current.shape[0]) and (y_>=0) and (y_<img_current.shape[1]):\n",
    "                if mask_begin[x_,y_] > 0:\n",
    "                    new_mask[x,y] = 255\n",
    "    return new_mask\n",
    "\n",
    "def propagate_mask_direct(nb_start, nb_end, name_in_the_figure):\n",
    "    # generate all the propagated masks for the direct method\n",
    "\n",
    "    original_mask = imread(f\"./sequences-train/{name_in_the_figure}-001.png\")\n",
    "    first_img = imread(f'./sequences-train/{name_in_the_figure}-001.bmp')\n",
    "    imwrite( f\"./my_results/{name_in_the_figure}-mask_pro-001-001.png\", original_mask) # For coherence when reading them later\n",
    "\n",
    "\n",
    "    for i in range(nb_start+1, nb_end+1):\n",
    "        flow = np.load( f\"./my_results/{name_in_the_figure}-001-\" + str(i).zfill(3) + '.npy')    \n",
    "        current_mask = propagate_mask(flow, img_current= first_img, mask_begin = original_mask)\n",
    "\n",
    "        imwrite( f\"./my_results/{name_in_the_figure}-mask_pro-001-\"+ str(i).zfill(3) +'.png', current_mask)\n",
    "\n",
    "    print(\"End of mask propagation for direct integration\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "=> using pre-trained model 'flownets'\n",
      "End of flow calculation for direct integration\n",
      "End of mask propagation for direct integration\n"
     ]
    }
   ],
   "source": [
    "nb_start = 1\n",
    "nb_end   = 50\n",
    "\n",
    "device = set_cuda()\n",
    "model, div_flow = load_model(path_to_model, device)\n",
    "inference_direct(nb_start,nb_end, \"swan\", device, model, div_flow)\n",
    "\n",
    "propagate_mask_direct(nb_start, nb_end, \"swan\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
